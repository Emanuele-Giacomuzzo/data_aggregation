\section*{Methods: clustering techniques}

	To cluster similar nodes, we used the following clustering techinques.

	\subsection*{Hierarchical clustering with Jaccard index}

		As a first clustering method, we clustered structurally equivalent nodes as in \citet{Yodzis1999}, using the Jaccard similarity index as a measure of structural equivalence. See Appendix \ref{appendix:jaccard} for the clustering algorithm.

	\subsection*{Hierarchical clustering with REGE index}

		As a second clustering method, we clustered regularly equivalent nodes as in \citet{Luczkovich2003}, using REGE index as a measure of regular equivalence. See Appendix \ref{appendix:rege} for the clustering algorithm.

	\subsection*{Clustering of density-based modules}

		As a third clustering method, we clustered the nodes inside the modules found by maximising the density-modularity, as in \citet{Guimera2010}. This type of modularity is expressed as the number of extra links present within the modules compared to the ones expected by chance. For directed networks, it can be expressed through the following equation of \citet{Arenas2007}, which is a generalisation of the Newman-Girvan modularity \citep{Newman2004}:

						\begin{equation}
							Q=\frac{1}{L}\sum\limits_{ij}[A_{ij}-\frac{k_i^{in}k_j^{out}}{L}]\delta_{m_im_j} \label{eqn:modularitydensity}
						\end{equation}

		\noindent where $Q$ is the directed modularity of partition P, $L$ is the number of links in the network, $A_{ij}$ is the element of the adjacency matrix of a directed, binary network (links go from $j$ to $i$), $k_i^{in}k_j^{out}/L$ is the probability of having an edge between $i$ and $j$, $k^{in}_i$ is the indegree of $i$ and $k^{out}_j$ is the out-degree of $j$), $ m_i$ is the module of $i$, and $\delta$ is the Kronecker delta \citep{Kozen2007}.

		The number and composition of the modules were found by using the Leiden algorithm of \citet{Traag2019}. This algorithm is an extension of the Louvain algorithm \citep{Blondel2008}. The latter is one of the best performing and fastes for community detection \citep{Traag2019}. However, it tends to produce communities that are arbitrarly poorly connected from each other and sometimes even disconnected. The Leiden algorithm not only solves this problem by producing better connected communities but it is also faster. The code that we used was implemented in the igraph package \citep{Csardi2006} for R \citep{RDevelopmentCoreTeam2011}.

	\subsection*{Clustering of prey-based and predator-based modules}

		As fourth and fifth clustering methods, we clustered the nodes of every module that was found by maximising the prey-modularity and the predator-modularity of the food web, as in \citet{Guimera2010}. In this case, the modularity of the food web is expressed as to how much different nodes connect to the same predators (for prey-modularity) or preys (for predator-modularity) than expected by chance. Mathematically, it can be expressed by the following equation \citep{Guimera2007} for prey-modularity

						\begin{equation}
							Q=\sum_{ij}{\left[\frac{c_{ij}^{out}}{\sum_{l}{k_l^{in}\left(k_l^{in}-1\right)}}-\frac{k_i^{out}k_j^{out}}{\left(\sum_{l} k_l^{in}\right)^2}\right]\delta_{m_im_j}}
						\end{equation}

		or in the following one for predator-modularity

						\begin{equation}
							Q=\sum_{ij}{\left[\frac{c_{ij}^{in}}{\sum_{l}{k_l^{out}\left(k_l^{out}-1\right)}}-\frac{k_i^{in}k_j^{in}}{\left(\sum_{l} k_l^{out}\right)^2}\right]\delta_{m_im_j}}
						\end{equation}

		\noindent where $c_{ij}^{out}$ is the number of outgoing links that i and j have in common and $c_{ij}^{in}$ is the number of incoming links that i and j have in common.
		We maximised this type of modules by using the rnetcarto package \citep{Doulcier2015} for R. This finds the community structure of the network by using simulated annealing \citep{Kirkpatrick1983}.  %CHANGE

	\subsection*{Clustering of groups}

		As a sixth clustering method, we clustered the nodes inside the modules found by the group model of \citep{Allesina2009a}. This model finds the modules that maximise the probability of randomly retrieving the food web by generating a modular version of an Erdős-Rényi random graph. For an arbitrary number of groups $k$, the probability of retrieving the food web is:

				\begin{equation}
					P(N(S,L)|\vec{p}^{\,})=\prod_{i=1}^k\prod_{j=1}^k p_{ij}^{L_{ij}} (1-p_{ij})^{S_i S_j - L_{ij}}
				\end{equation}

		\noindent where $N(S,L)$ is the food web N with S number of nodes and L number of links,  $\vec{p}^{\,}$ is the vector containing the probabilities of a connection between and within clusters, $p_{ij}$ is the probability that a node inside the group $i$ connects to another node inside the group $j$, $L_{ij}$ is the number of links connecting nodes belonging to the group i to nodes belonging to the group j, $S_i$ is the number of nodes in the cluster i,  and $S_j$ is the number of nodes in the cluster j.

		Because of the high number of possible module arrangments, it is not possible to explore them all. To find the best possible solution that our computation power allows us to find, we used the algorithm of \citet{Sander2015}. This relies on a Metropolis-Coupled Markov Chain Monte Carlo ($MC^3$), also known as parallel tempering\citep{Geyer1991}, with a Gibbs sampler \citep{Yildirim2012}. $MC^3$ can be considered as a Markov chain Monte Carlo (MCMC) with multiple chains running all at once \citep{Sander2015}.

\section*{Methods: connecting the clusters and assigning interaction strength}

	The wiring of the food web followed a similar approach to the one describe in \citet{Martinez1991}. We used five methods to decide whether there was a link between two clusters. The first method produced the maximum connectance and is known as maximum linkage. Here, a cluster had a connection to another cluster if it had at least one link going from one of its nodes to the nodes of the second cluster. The second one produced the minimum connectance and is known as minimum linkage. This time, a cluster was connected to another only if all its nodes had a connection to all the nodes of the other cluster. The other three methods produced an intermediate connectance. They considered a link from a cluster to the other only if at least 25\%, 50\% or 70\% of possible connections from the first cluster to the second were realised.

	The weight of the link was then calculated in four different ways: as the minimum weight, the maximum weight, the mean weight, and the sum of the weights of the links going from the members of the first cluster to the ones of the second cluster.

\section*{Methods: centrality indices}

	For each food web, we calculated the centrality indices before and after the aggregation. The centrality index of a node after the aggregation process equaled the one of its cluster. For example, let's consider a hypothetical aggregation. Before the aggregation, the node "hake" has a degree centrality of 5. Through the  aggregation process, this happens to be aggregated into a fish cluster. The degree centrality of this fish cluster is 8. The degree centrality of hake was 5 before the aggregation and 8 after the aggregation.

	\subsection*{Degree centrality (DC)}

		The degree centrality ($DC$) of a node $i$ is the number of links it has \citep{Wasserman1994}

					\begin{equation}
								DC_i=\sum_{j=1}^{n}A_{ij}
					\end{equation}

		\noindent where $n$ is the number of nodes in the food web, and $A_{ij}$ is the element of the adjacency matrix, after the network has been transformed in a binary undirected one. It can be normalised by dividing it by the total number of possible connections that a node could have \citep{Wasserman1994}

					\begin{equation}
								nDC_i=\frac{DC_i}{n-1}\ \ \
					\end{equation}

		\noindent where $n-1$ is the maximum number of connections the node can have. The minus one shows that a node cannot have a connection to itself.

		Another type of degree centrality that we considered was the weighted degree centrality ($wDC$), often referred to as node strength. Its formula, as well as the formula of its normalised version, are the same as for the non-weighted degree centrality. This time, however, the adjacency matrix is of an undirected weighted network \citep{Fornito2016}.

					\begin{equation}
								WDC_i=\sum_{j=1}^{n}A_{ij}
					\end{equation}

	\subsection*{Closeness centrality (CC)}

		The closeness centrality ($CC$) of a node is the average distance a node from all the others \citep{Wasserman1994}

					\begin{equation}
								CC_i=\frac{1}{\sum\limits_{j=1}^n d(i,j)}
					\end{equation}

		\noindent where $d(i,j)$ is the shortest path between node $i$ and $j$. It can be normalised as follows \citep{Wasserman1994}

					\begin{equation}
								nCC_i=\frac{n-1}{\sum\limits_{j=1}^n d(i,j)}
					\end{equation}

	\subsection*{Betweenness centrality (BC)}

		The betweenness centrality ($BC$) of a node is the average number of times that it acts as a bridge along the shortest path between two other nodes. It can be  mathematically expressed as follows \citep{Wasserman1994}

						\begin{equation}
							BC_i=\sum_{i\neq m\neq n}\frac{\sigma_{mn}\left(i\right)}{\sigma_{mn}}
						\end{equation}

		\noindent where $\sigma_{mn}$ is the total number of shortest paths going from $s$ to $t$ and $\sigma_{mn}\left(i\right)$ is the total number of these paths passing through $i$. It can be normalised with the following equation \citep{Wasserman1994}

						\begin{equation}
							nBC_i=\frac{BC_i}{\left(n-1\right)\left(n-2\right)/2}
						\end{equation}

	\subsection*{Status index (s)}

		The status index of a node is the sum of its distances from all the other nodes inside the network, calculated as their shortest paths following a bottom-up direction \citep{Endredi2018}

						\begin{equation}
							s_i=\sum_{j=1}^{n}d\left(i,j\right).
						\end{equation}

		It was first introduced to social networks, followed two years later by its application to food webs by \citet{Harary1959, Harary1961}. By following the same method but in a top-down direction we obtain the controstatus $(s_i’)$

						\begin{equation}
							s_i^\prime=\sum_{j=1}^{n}d\left(i,j\right).
						\end{equation}

		The difference between the status and the controstatus is called the net status ($\Delta s_i$)

						\begin{equation}
							\Delta s_i=s_i-s_i^\prime.
						\end{equation}

	\subsection*{Keystone index (K)}

		The keystone index was firstly introduced by \citet{Jordan1999} and inspired by the status index. As the status index family, the keystone index of a species $i$ ($K(i)$) is calculated by considering the bottom-up and the top-down effects separately \citet{Jordan2006}

						\begin{equation}
							K\left(i\right)=K_b\left(i\right)+K_t\left(i\right)
						\end{equation}

		\noindent where $K_b\left(i\right)$ is its bottom-up keystone index of species $i$ and $K_t\left(i\right)$ the top-down keystone index of species $i$.

		Unlike the status index, which only considers the distance between a node and all the other nodes, the keystone index takes into consideration how the size of a certain effect gets split between the different neighbours of a node. Every time the effect reaches a certain node connected to multiple nodes, the following nodes receive only a fraction of the total effect. For example, when considering the bottom-up effect, if the prey has two predators, the bottom-up effect received by each predator will be half. The bottom-up effect of a certain node $(K_b\left(i\right))i$ is then calculated in the following way

						\begin{equation}
							K_b\left(i\right)=\sum_{j=1}^{n}\frac{1}{m\left(i\right)\left(j\right)}+\frac{K_b\left(j\right)}{m\left(i\right)\left(j\right)}
						\end{equation}

		\noindent where $j$ is a predator of $I$,$m(i)(j)$ is the number of preys of $j$, and $\frac{K_b\left(j\right)}{m\left(i\right)\left(j\right)}$ is the fraction of bottom-up effects of $j$ that are caused by $i$. The $K_b\left(j\right)$of top predators is set as 0. The top-down effect of a certain node $K_t\left(i\right)$ is calculated exactly as $K_b\left(i\right)$, but with the direction of the links inverted. The bottom-up and the top-down effects can also be split into their direct and indirect component. The indirect component takes into consideration the bottom-up effects of the predator and direct component does not

					\begin{equation}
						K_{b,indirect}\left(i\right)=\sum_{j=1}^{n}\frac{1}{m\left(i\right)\left(j\right)}+\frac{K_b\left(j\right)}{m\left(i\right)\left(j\right)}
					\end{equation}

					\begin{equation}
						K_{b,direct}\left(i\right)=\sum_{j=1}^{n}\frac{1}{m\left(i\right)\left(j\right)}+\frac{1}{m\left(i\right)\left(j\right)}
					\end{equation}

		The direct and indirect components of the top-down effect are calculated in the same way, but with the direction of the links inverted. The direct and indirect keystone indices of a node are the sum of its direct/indirect bottom-up effects and its direct/indirect top-down effects

					\begin{equation}
						K_{direct}(i)=K_{b,direct}+K_{t,direct}
					\end{equation}

					\begin{equation}
						K_{indirect}(i)=K_{b,indirect}+K_{t,indirect}
					\end{equation}

		The keystone index not only is the sum of its top-down and bottom-up effects, but also the sum of its direct and indirect effects

					\begin{equation}
						K\left(i\right)=K_{dir}\left(i\right)+K_{indir}\left(i\right)
					\end{equation}

	\subsection*{Topological importance (TI)}

		The topological importance of a node represents its potential to create bottom-up effects on other species, up to a certain number of steps that we can set. It was first introduced to host-parasitoid networks by \citet{Muller1999} and then to food webs by \citet{Jordan2003}. The algorithm of its computation is reported in Appendix \ref{appendix:TI} \citep{Jordan2009}.



		Topological importance can be also used for weighted networks - giving us weighted topological importance ($WI$) – if instead of using the degree ($D$) we use the weighted degree ($WD$) \citep{Scotti2007}

						\begin{equation}
							a_{1,ji}=\frac{A_{ij}}{weighted\:indegree_j}
						\end{equation}

		\noindent where $A_{ij}$ is the element of the adjacency matrix of the weighted directed network.

	\subsection*{Trophic field overlap (TO) & species uniqueness (STO)}

		The trophic field overlap (TO) represents how redundant the strong interactions of a node are. It was first introduced by \citet{Jordan2009a}. It is the number of times that it and another node interact strongly with the same predator. The algorithm for its computation can be found in Appendix \ref{appendix:TO} \citep{Jordan2018}.


		Trophic field overlap can be also used for weighted networks – giving us weighted trophic field overlap (WO) – if instead of using the degree (D) we use the weighted degree, (e.g., \citet{Xiao2019})

						\begin{equation}
							a_{1,ij}=\frac{A_{ij}}{D_j}
						\end{equation}

		Finally, to avoid the bias of choosing a wrong threshold, we chose multiple thresholds and summed the TO of a species i for each of these thresholds. This gave us the species uniqueness (STO), an index that was firstly introduced by \citet{Lai2015}.

\section*{Methods: statistical analysis}

	The combination of clusterings (6 methods), linkages (5 methods) and interaction strength determinations (4 methods) produced 120 aggregation methods. For each of these aggregation methods, we studied their effects on centrality indices. More in particular, for each centrality index we studied how the nodes were ranked before and after the process. It was possible to study the difference in the these two rankings by using Kendall's tau b ($\tau_B$) - a version of Kendall's rank correlation coefficient that makes adjustments for ties \citep{Agresti2012}. For each aggregation method and for each centrality index, we found the mean $\tau_B$ across all food webs. This required us to convert $\tau_B$ using the Fisher z-transformation \citep{Fisher1915}, find the mean and back-transform it. For each mean $\tau_B$ we found its confidence interval by bootstrapping \citep{DiCiccio1996}. $\tau_B$ and bootstrapping were implemented in the Statistics and Machine Learning Toolbox for MATLAB \citep{MathworksInc.2019}.
